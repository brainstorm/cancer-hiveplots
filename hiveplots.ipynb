{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import subprocess\n",
    "import commands\n",
    "import gzip\n",
    "import glob\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from pyveplot import *\n",
    "#from collections import namedtuple\n",
    "import networkx as nx\n",
    "import random\n",
    "from IPython.display import SVG\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circos vs Hiveplots\n",
    "\n",
    "This notebook attemps to find alternative, clearer plots for inter and intra-chromosomal structural variations. In other words, the idea is to go from\n",
    "\n",
    "A typical Circos plot:\n",
    "\n",
    "<img src=\"https://www.genomatix.de/online_help/help_regionminer/SV_circos_genome.png\" height=300 width=300/>\n",
    "\n",
    "To this:\n",
    "\n",
    "<img src=\"img/hyplot_intra_inter.png\"/>\n",
    "\n",
    "From this:\n",
    "\n",
    "<img src=\"img/sv_table.png\"/>\n",
    "\n",
    "Some of the preliminary data comes from [Australian Pancreatic Cancer Genome Initiative](http://www.pancreaticcancer.net.au/), other from the [ICGC-TCGA DREAM challenge](https://www.synapse.org/#!Synapse:syn312572) processed via the [bcbio cancer pipeline](https://bcbio-nextgen.readthedocs.org/en/latest/contents/pipelines.html#cancer-variant-calling). That pipeline run takes a considerable amount of time to run given the big input sizes and [running several variant callers](http://bcb.io/2015/03/05/cancerval/).\n",
    "\n",
    "For pedagogical reasons, the resulting tab-separated `.tsv` files have been generated for easy analysis. If a more upstream run or (re)-analysis  is required, there's [reduced dataset that focuses on chromosome 6](https://bcbio-nextgen.readthedocs.org/en/latest/contents/teaching.html).\n",
    "\n",
    "After filtering VCF's resulting from both [Manta](https://github.com/Illumina/manta) variant caller and [Lumpy](https://github.com/arq5x/lumpy-sv) with a simple [vawk expression](https://github.com/cc2qe/vawk):\n",
    "\n",
    "<pre>\n",
    "gzcat manta-variants.vcf.gz | vawk '{{if (($12 == \"PASS\")) print $1, $4, $11, $17 }}'\n",
    "</pre>\n",
    "\n",
    "A svtools script, [`vcfToBedpe`](https://raw.githubusercontent.com/hall-lab/svtools/master/bin/vcftobedpe), was used to convert a plain [VCF](https://samtools.github.io/hts-specs/VCFv4.2.pdf) to [BEDPE format](http://bedtools.readthedocs.org/en/latest/content/general-usage.html#bedpe-format) to generate a paired end version where structural variations are seen as pairs (`chrom` and `chrom_b` columns).\n",
    "\n",
    "Finally, [pyveplot](https://github.com/CSB-IG/pyveplot), a Python implementation of [Hive plots](http://www.hiveplot.net/) was used to show the representation above.\n",
    "\n",
    "A Hive plot is a perceptually uniform and scalable linear layout visualization for network visual analytics (doi: 10.1093/bib/bbr069).\n",
    "\n",
    "<img src=\"img/hiveplot-thisisuseful.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vcf_data = \"data/vcf\"\n",
    "tsv_data = \"data/tsv\"\n",
    "ev_data = \"data/sv_size\"\n",
    "\n",
    "event_colors = {'DEL': 'red',\n",
    "                'INV': 'yellow',\n",
    "                'DUP': 'blue',\n",
    "                'BND': 'green',\n",
    "                'complex': 'purple'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a hiveplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hiveplot(fname, dataframe):\n",
    "    # Remove duplicates and filter out ALTS (GL000226.1, GL000224.1 ...)\n",
    "    #dataframe = dataframe[~dataframe[\"chrom\"].str.contains(\"GL\")]\n",
    "    dataframe = dataframe.drop_duplicates(keep=\"first\") ## XXX: Perhaps should group/count dups better?\n",
    "    \n",
    "    # a network\n",
    "    g = nx.Graph()\n",
    "\n",
    "    # our hiveplot object\n",
    "    h = Hiveplot('{}.svg'.format(fname))\n",
    "\n",
    "                  # start      end\n",
    "    axis0 = Axis((200,200), (200,100), stroke=\"grey\")\n",
    "    axis1 = Axis((200,200), (300,300), stroke=\"blue\", stroke_width=1.2)\n",
    "    axis2 = Axis((200,200), (10,310), stroke=\"black\", stroke_width=3)\n",
    "\n",
    "    h.axes = [ axis0, axis1, axis2 ]\n",
    "    \n",
    "    #print \"Structural variation events for ''{fname}'' have the following counts:\\n\\n{groupby}\\n\".format(\n",
    "    #       groupby=dataframe.groupby(\"sv\").count(), fname=fname)\n",
    "    \n",
    "    for row in dataframe.itertuples():\n",
    "        # idx, u'sample', u'chrom', u'chrom_b', u'sv', u'counts'\n",
    "        g.add_node(row[2])\n",
    "        # Count = 1 looks better than parametrized with groupby\n",
    "        g.add_edge(row[2], row[3], event=row[4], count=1)\n",
    "\n",
    "    for n in g.nodes():\n",
    "        # Separate instances for the axis, otherwise arcs go to itself.\n",
    "        node = Node(n)\n",
    "        node2 = Node(n)\n",
    "        node3 = Node(n)\n",
    "\n",
    "        # XXX: Find a better (more uniform) function than ord? \n",
    "        # A small hash function would be prob better here.\n",
    "        # Calculates the offset of the chromosomes in the axis.\n",
    "\n",
    "        off = 120\n",
    "        n = str(n)\n",
    "        \n",
    "        if len(n) == 1:\n",
    "            offset_axis0 = ord(n)\n",
    "            offset_axis1 = ord(n)\n",
    "            offset_axis2 = ord(n)\n",
    "        else:\n",
    "            chrom_offset = 0\n",
    "            for char in n:\n",
    "                chrom_offset = chrom_offset + ord(char)\n",
    "\n",
    "            offset_axis0 = chrom_offset\n",
    "            offset_axis1 = chrom_offset\n",
    "            offset_axis2 = chrom_offset\n",
    "\n",
    "        offset_axis0 = offset_axis0/off\n",
    "        offset_axis1 = offset_axis1/off\n",
    "        offset_axis2 = offset_axis2/off\n",
    "\n",
    "        axis0.add_node(node, offset_axis0)\n",
    "        axis1.add_node(node2, offset_axis1)\n",
    "        axis2.add_node(node3, offset_axis2)\n",
    "\n",
    "    for e in g.edges():\n",
    "        edge_data = g.get_edge_data(*e)\n",
    "\n",
    "        # inter-chromosomal axis\n",
    "        if e[0] != e[1] and (e[0] in axis0.nodes) and (e[1] in axis1.nodes):\n",
    "            h.connect(axis0, e[0], 45, \n",
    "                      axis1, e[1], -45, \n",
    "                      stroke_width=edge_data['count'], \n",
    "                      stroke=event_colors[edge_data['event']])\n",
    "        \n",
    "        # intra-chromosomal axis\n",
    "        elif e[0] == e[1] and (e[0] in axis1.nodes) and (e[1] in axis2.nodes):\n",
    "            h.connect(axis1, e[0], 15, \n",
    "                      axis2, e[1], -15, \n",
    "                      stroke_width=edge_data['count'], \n",
    "                      stroke=event_colors[edge_data['event']])\n",
    "\n",
    "    h.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shipped TSV's do not have the same structure, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(data):    \n",
    "    if \"counts\" not in data.columns:\n",
    "        data.columns = [\"chrom\", \"chrom_b\", \"sv\"]\n",
    "        data.insert(0, 'sample', np.nan)\n",
    "        data.insert(len(data.columns), 'counts', np.nan)\n",
    "    else:\n",
    "        data.insert(2, 'chrom_b', 0)\n",
    "\n",
    "    # Cleanup GL* alts\n",
    "    data = data[~data[\"chrom\"].str.contains(\"GL\")]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.97 ms, sys: 23 ms, total: 26.9 ms\n",
      "Wall time: 15.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for tumor in glob.iglob(os.path.join(vcf_data, \"*_Tumor*.vcf.gz\")):\n",
    "    # already converted to bedpe\n",
    "    if 'paired' in tumor:\n",
    "        continue\n",
    "    base_tumor_fn = os.path.splitext(os.path.splitext(tumor)[0]) \n",
    "    paired_fn = base_tumor_fn[0]+\".paired\"+\".vcf\"\n",
    "    final_tsv = os.path.join(tsv_data, os.path.basename(base_tumor_fn[0])+\".tsv\")\n",
    "    sv_size = os.path.join(ev_data, os.path.basename(base_tumor_fn[0])+\".tsv\")\n",
    "    \n",
    "    vcftope_cmd = ([\"vcftobedpe\", \"-i\", tumor, \"-o\", paired_fn])\n",
    "    \n",
    "    vawk_cmd = \"\"\"vawk '{{if (($12 == \"PASS\" || $7 == \".\") && (S$GT != \"0/0\")) \\\n",
    "                  print $1,$4,$11,$17}}' {paired_vcf} | \\\n",
    "                  grep -v GL > {tumor_tsv}\"\"\".format(paired_vcf=paired_fn, tumor_tsv=final_tsv)\n",
    "    \n",
    "    vawk_sv_size = \"\"\"vawk '{{if (($12 == \"PASS\" || $7 == \".\") && (S$GT != \"0/0\") && \\\n",
    "                  (S$SR > 5)) print $1,$2,$4,$5,$11,$17}}' {paired_vcf} | \\\n",
    "                  grep -v GL > {tumor_tsv}\"\"\".format(paired_vcf=paired_fn, tumor_tsv=sv_size)\n",
    "    \n",
    "    subprocess.check_call(vcftope_cmd)\n",
    "    commands.getstatusoutput(vawk_cmd)\n",
    "    commands.getstatusoutput(vawk_sv_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_summary_table(datasets):\n",
    "    \"\"\" A table with chr1-Y as rows, each sample as a column, \n",
    "        number of inter/intra-chromosomal events as data points.\n",
    "\n",
    "        :datasets: a tuple with several (data, sample_names) where data is the associated Pandas dataframe.\n",
    "    \"\"\"\n",
    "    chromosomes = [str(x) for x in range(1,23)]\n",
    "    chromosomes.append('X')\n",
    "    chromosomes.append('Y')\n",
    "    \n",
    "    samples = [x[1] for x in datasets]\n",
    "    \n",
    "    summary = pd.DataFrame(columns=samples, index=chromosomes)\n",
    "    \n",
    "    for data, sample in datasets:\n",
    "        # Uncomment and tweak code below if one wants totals, not by chromosome\n",
    "        #intra_chrom = len(data[data['chrom'] == data['chrom_b']].index)\n",
    "        #inter_chrom = len(data[data['chrom'] != data['chrom_b']].index)\n",
    "        \n",
    "        for chrom in chromosomes:\n",
    "            intra_specific_chrom = len(data[((data['chrom'] == chrom) | (data['chrom_b'] == chrom)) & (data['chrom'] == data['chrom_b'])].index)\n",
    "            inter_specific_chrom = len(data[((data['chrom'] == chrom) | (data['chrom_b'] == chrom)) & (data['chrom'] != data['chrom_b'])].index)\n",
    "            \n",
    "            summary.loc[chrom][sample] = (intra_specific_chrom, inter_specific_chrom)\n",
    "        \n",
    "        #print data.groupby(['sv', 'chrom'])['chrom'].count()\n",
    "        \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def event_size_distr(dataset):\n",
    "    \"\"\"Can you get the size distribution of events out of the VCF (for the intrachromosomal SVs only)? \n",
    "       Wonder if this is Lumpy calling tons of short to mid-sized Indels. \n",
    "    \"\"\"\n",
    "    df = pd.read_table(dataset, dtype=object, names = [\"chrom_a\", \"pos_a\", \"chrom_b\", \"pos_b\", \"sv\"])\n",
    "    # Only intra-chromosomal, positions between distant chroms can be misleading\n",
    "    df = df[df['chrom_a'] == df['chrom_b']]\n",
    "    df[\"size\"] = abs(np.int64(df[\"pos_b\"]) - np.int64(df[\"pos_a\"]))\n",
    "    #size_distr = df.groupby(['sv', 'chrom_a'])['size']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process and plot all the TSV's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples = []\n",
    "samples_size_distr = []\n",
    "\n",
    "for dataset in glob.iglob(os.path.join(tsv_data, \"*.tsv\")):\n",
    "    dataset_name = os.path.basename(dataset)\n",
    "    event_sizes = os.path.join(ev_data, os.path.basename(dataset))\n",
    "    \n",
    "    study = pd.read_table(dataset, dtype=object)\n",
    "    study = normalize(study)\n",
    "    \n",
    "    samples.append((study, dataset_name))\n",
    "    samples_size_distr.append((event_sizes, event_size_distr(event_sizes)))\n",
    "    \n",
    "    # plot them all\n",
    "    hiveplot(dataset_name, study)\n",
    "\n",
    "sample_summary_table(samples).to_excel(\"noSRfilter.xls\")\n",
    "#for fname, data in samples_size_distr:\n",
    "#    print fname\n",
    "    #print data[['chrom_a', 'chrom_b', 'sv', 'size']]\n",
    "#    data.groupby(['sv'])['size'].mean().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
