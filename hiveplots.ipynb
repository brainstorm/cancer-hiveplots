{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import subprocess\n",
    "import commands\n",
    "import gzip\n",
    "import glob\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from pyveplot import *\n",
    "#from collections import namedtuple\n",
    "import networkx as nx\n",
    "import random\n",
    "from IPython.display import SVG\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circos vs Hiveplots\n",
    "\n",
    "This notebook attemps to find alternative, clearer plots for inter and intra-chromosomal structural variations. In other words, the idea is to go from\n",
    "\n",
    "A typical Circos plot:\n",
    "\n",
    "<img src=\"https://www.genomatix.de/online_help/help_regionminer/SV_circos_genome.png\" height=300 width=300/>\n",
    "\n",
    "To this:\n",
    "\n",
    "<img src=\"img/hyplot_intra_inter.png\"/>\n",
    "\n",
    "From this:\n",
    "\n",
    "<img src=\"img/sv_table.png\"/>\n",
    "\n",
    "Some of the preliminary data comes from [Australian Pancreatic Cancer Genome Initiative](http://www.pancreaticcancer.net.au/), other from the [ICGC-TCGA DREAM challenge](https://www.synapse.org/#!Synapse:syn312572) processed via the [bcbio cancer pipeline](https://bcbio-nextgen.readthedocs.org/en/latest/contents/pipelines.html#cancer-variant-calling). That pipeline run takes a considerable amount of time to run given the big input sizes and [running several variant callers](http://bcb.io/2015/03/05/cancerval/).\n",
    "\n",
    "For pedagogical reasons, the resulting tab-separated `.tsv` files have been generated for easy analysis. If a more upstream run or (re)-analysis  is required, there's [reduced dataset that focuses on chromosome 6](https://bcbio-nextgen.readthedocs.org/en/latest/contents/teaching.html).\n",
    "\n",
    "After filtering VCF's resulting from both [Manta](https://github.com/Illumina/manta) variant caller and [Lumpy](https://github.com/arq5x/lumpy-sv) with a simple [vawk expression](https://github.com/cc2qe/vawk):\n",
    "\n",
    "<pre>\n",
    "gzcat manta-variants.vcf.gz | vawk '{{if (($12 == \"PASS\")) print $1, $4, $11, $17 }}'\n",
    "</pre>\n",
    "\n",
    "A svtools script, [`vcfToBedpe`](https://raw.githubusercontent.com/hall-lab/svtools/master/bin/vcftobedpe), was used to convert a plain [VCF](https://samtools.github.io/hts-specs/VCFv4.2.pdf) to [BEDPE format](http://bedtools.readthedocs.org/en/latest/content/general-usage.html#bedpe-format) to generate a paired end version where structural variations are seen as pairs (`chrom` and `chrom_b` columns).\n",
    "\n",
    "Finally, [pyveplot](https://github.com/CSB-IG/pyveplot), a Python implementation of [Hive plots](http://www.hiveplot.net/) was used to show the representation above.\n",
    "\n",
    "A Hive plot is a perceptually uniform and scalable linear layout visualization for network visual analytics (doi: 10.1093/bib/bbr069).\n",
    "\n",
    "<img src=\"img/hiveplot-thisisuseful.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vcf_data = \"data/vcf\"\n",
    "tsv_data = \"data/tsv\"\n",
    "ev_data = \"data/sv_size\"\n",
    "\n",
    "event_colors = {'DEL': 'red',\n",
    "                'INV': 'yellow',\n",
    "                'DUP': 'blue',\n",
    "                'BND': 'green',\n",
    "                'complex': 'purple'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a hiveplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hiveplot(fname, dataframe):\n",
    "    # Remove duplicates and filter out ALTS (GL000226.1, GL000224.1 ...)\n",
    "    #dataframe = dataframe[~dataframe[\"chrom\"].str.contains(\"GL\")]\n",
    "    dataframe = dataframe.drop_duplicates(keep=\"first\") ## XXX: Perhaps should group/count dups better?\n",
    "    \n",
    "    # a network\n",
    "    g = nx.Graph()\n",
    "\n",
    "    # our hiveplot object\n",
    "    h = Hiveplot('{}.svg'.format(fname))\n",
    "\n",
    "                  # start      end\n",
    "    axis0 = Axis((200,200), (200,100), stroke=\"grey\")\n",
    "    axis1 = Axis((200,200), (300,300), stroke=\"blue\", stroke_width=1.2)\n",
    "    axis2 = Axis((200,200), (10,310), stroke=\"black\", stroke_width=3)\n",
    "\n",
    "    h.axes = [ axis0, axis1, axis2 ]\n",
    "    \n",
    "    #print \"Structural variation events for ''{fname}'' have the following counts:\\n\\n{groupby}\\n\".format(\n",
    "    #       groupby=dataframe.groupby(\"sv\").count(), fname=fname)\n",
    "    \n",
    "    for row in dataframe.itertuples():\n",
    "        # idx, u'sample', u'chrom', u'chrom_b', u'sv', u'counts'\n",
    "        g.add_node(row[2])\n",
    "        # Count = 1 looks better than parametrized with groupby\n",
    "        g.add_edge(row[2], row[3], event=row[4], count=1)\n",
    "\n",
    "    for n in g.nodes():\n",
    "        # Separate instances for the axis, otherwise arcs go to itself.\n",
    "        node = Node(n)\n",
    "        node2 = Node(n)\n",
    "        node3 = Node(n)\n",
    "\n",
    "        # XXX: Find a better (more uniform) function than ord? \n",
    "        # A small hash function would be prob better here.\n",
    "        # Calculates the offset of the chromosomes in the axis.\n",
    "\n",
    "        off = 120\n",
    "        n = str(n)\n",
    "        \n",
    "        if len(n) == 1:\n",
    "            offset_axis0 = ord(n)\n",
    "            offset_axis1 = ord(n)\n",
    "            offset_axis2 = ord(n)\n",
    "        else:\n",
    "            chrom_offset = 0\n",
    "            for char in n:\n",
    "                chrom_offset = chrom_offset + ord(char)\n",
    "\n",
    "            offset_axis0 = chrom_offset\n",
    "            offset_axis1 = chrom_offset\n",
    "            offset_axis2 = chrom_offset\n",
    "\n",
    "        offset_axis0 = offset_axis0/off\n",
    "        offset_axis1 = offset_axis1/off\n",
    "        offset_axis2 = offset_axis2/off\n",
    "\n",
    "        axis0.add_node(node, offset_axis0)\n",
    "        axis1.add_node(node2, offset_axis1)\n",
    "        axis2.add_node(node3, offset_axis2)\n",
    "\n",
    "    for e in g.edges():\n",
    "        edge_data = g.get_edge_data(*e)\n",
    "\n",
    "        # inter-chromosomal axis\n",
    "        if e[0] != e[1] and (e[0] in axis0.nodes) and (e[1] in axis1.nodes):\n",
    "            h.connect(axis0, e[0], 45, \n",
    "                      axis1, e[1], -45, \n",
    "                      stroke_width=edge_data['count'], \n",
    "                      stroke=event_colors[edge_data['event']])\n",
    "        \n",
    "        # intra-chromosomal axis\n",
    "        elif e[0] == e[1] and (e[0] in axis1.nodes) and (e[1] in axis2.nodes):\n",
    "            h.connect(axis1, e[0], 15, \n",
    "                      axis2, e[1], -15, \n",
    "                      stroke_width=edge_data['count'], \n",
    "                      stroke=event_colors[edge_data['event']])\n",
    "\n",
    "    h.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shipped TSV's do not have the same structure, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(data):    \n",
    "    if \"counts\" not in data.columns:\n",
    "        data.columns = [\"chrom\", \"chrom_b\", \"sv\"]\n",
    "        data.insert(0, 'sample', np.nan)\n",
    "        data.insert(len(data.columns), 'counts', np.nan)\n",
    "    else:\n",
    "        data.insert(2, 'chrom_b', 0)\n",
    "\n",
    "    # Cleanup GL* alts\n",
    "    data = data[~data[\"chrom\"].str.contains(\"GL\")]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.62 ms, sys: 20.7 ms, total: 24.3 ms\n",
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for tumor in glob.iglob(os.path.join(vcf_data, \"*_Tumor*.vcf.gz\")):\n",
    "    # already converted to bedpe\n",
    "    if 'paired' in tumor:\n",
    "        continue\n",
    "    base_tumor_fn = os.path.splitext(os.path.splitext(tumor)[0]) \n",
    "    paired_fn = base_tumor_fn[0]+\".paired\"+\".vcf\"\n",
    "    final_tsv = os.path.join(tsv_data, os.path.basename(base_tumor_fn[0])+\".tsv\")\n",
    "    sv_size = os.path.join(ev_data, os.path.basename(base_tumor_fn[0])+\".tsv\")\n",
    "    \n",
    "    vcftope_cmd = ([\"vcftobedpe\", \"-i\", tumor, \"-o\", paired_fn])\n",
    "    \n",
    "    vawk_cmd = \"\"\"vawk '{{if (($12 == \"PASS\" || $7 == \".\") && (S$GT != \"0/0\") && \\\n",
    "                  (S$SR > 5)) print $1,$4,$11,$17}}' {paired_vcf} | \\\n",
    "                  grep -v GL > {tumor_tsv}\"\"\".format(paired_vcf=paired_fn, tumor_tsv=final_tsv)\n",
    "    \n",
    "    vawk_sv_size = \"\"\"vawk '{{if (($12 == \"PASS\" || $7 == \".\") && (S$GT != \"0/0\") && \\\n",
    "                  (S$SR > 5)) print $1,$2,$4,$5,$11,$17}}' {paired_vcf} | \\\n",
    "                  grep -v GL > {tumor_tsv}\"\"\".format(paired_vcf=paired_fn, tumor_tsv=sv_size)\n",
    "    \n",
    "    subprocess.check_call(vcftope_cmd)\n",
    "    commands.getstatusoutput(vawk_cmd)\n",
    "    commands.getstatusoutput(vawk_sv_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_summary_table(datasets):\n",
    "    \"\"\" A table with chr1-Y as rows, each sample as a column, \n",
    "        number of inter/intra-chromosomal events as data points.\n",
    "\n",
    "        :datasets: a tuple with several (data, sample_names) where data is the associated Pandas dataframe.\n",
    "    \"\"\"\n",
    "    chromosomes = [str(x) for x in range(1,23)]\n",
    "    chromosomes.append('X')\n",
    "    chromosomes.append('Y')\n",
    "    \n",
    "    samples = [x[1] for x in datasets]\n",
    "    \n",
    "    summary = pd.DataFrame(columns=samples, index=chromosomes)\n",
    "    \n",
    "    for data, sample in datasets:\n",
    "        # Uncomment and tweak code below if one wants totals, not by chromosome\n",
    "        #intra_chrom = len(data[data['chrom'] == data['chrom_b']].index)\n",
    "        #inter_chrom = len(data[data['chrom'] != data['chrom_b']].index)\n",
    "        \n",
    "        for chrom in chromosomes:\n",
    "            intra_specific_chrom = len(data[((data['chrom'] == chrom) | (data['chrom_b'] == chrom)) & (data['chrom'] == data['chrom_b'])].index)\n",
    "            inter_specific_chrom = len(data[((data['chrom'] == chrom) | (data['chrom_b'] == chrom)) & (data['chrom'] != data['chrom_b'])].index)\n",
    "            \n",
    "            summary.loc[chrom][sample] = (intra_specific_chrom, inter_specific_chrom)\n",
    "        \n",
    "        #print data.groupby(['sv', 'chrom'])['chrom'].count()\n",
    "        \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def event_size_distr(dataset):\n",
    "    \"\"\"Can you get the size distribution of events out of the VCF (for the intrachromosomal SVs only)? \n",
    "       Wonder if this is Lumpy calling tons of short to mid-sized Indels. \n",
    "    \"\"\"\n",
    "    df = pd.read_table(dataset, dtype=object, names = [\"chrom_a\", \"pos_a\", \"chrom_b\", \"pos_b\", \"sv\"])\n",
    "    # Only intra-chromosomal, positions between distant chroms can be misleading\n",
    "    df = df[df['chrom_a'] == df['chrom_b']]\n",
    "    df[\"size\"] = abs(np.int64(df[\"pos_b\"]) - np.int64(df[\"pos_a\"]))\n",
    "    #size_distr = df.groupby(['sv', 'chrom_a'])['size']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process and plot all the TSV's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/sv_size/APGI1953_Tumor-lumpy.tsv\n",
      "sv        \n",
      "BND  count    2.380000e+02\n",
      "     mean     1.715578e+07\n",
      "     std      3.309279e+07\n",
      "     min      5.000000e+01\n",
      "     25%      1.712500e+02\n",
      "     50%      2.058285e+05\n",
      "     75%      1.675164e+07\n",
      "     max      1.798211e+08\n",
      "DEL  count    3.490000e+02\n",
      "     mean     5.589061e+06\n",
      "     std      1.956366e+07\n",
      "     min      1.900000e+01\n",
      "     25%      7.600000e+01\n",
      "     50%      3.100000e+02\n",
      "     75%      8.263000e+03\n",
      "     max      1.117998e+08\n",
      "DUP  count    1.770000e+02\n",
      "     mean     1.170300e+07\n",
      "     std      3.051701e+07\n",
      "     min      1.070000e+02\n",
      "     25%      5.390000e+02\n",
      "     50%      3.233000e+03\n",
      "     75%      8.744100e+04\n",
      "     max      1.470550e+08\n",
      "INV  count    3.000000e+01\n",
      "     mean     7.778667e+02\n",
      "     std      3.625828e+03\n",
      "     min      3.400000e+01\n",
      "     25%      7.025000e+01\n",
      "     50%      8.450000e+01\n",
      "     75%      1.130000e+02\n",
      "     max      1.996900e+04\n",
      "dtype: float64\n",
      "data/sv_size/APGI1953_Tumor-manta.tsv\n",
      "sv        \n",
      "DEL  count          51.000000\n",
      "     mean      1483107.078431\n",
      "     std       8809136.458843\n",
      "     min            51.000000\n",
      "     25%           157.000000\n",
      "     50%          1127.000000\n",
      "     75%          8990.000000\n",
      "     max      62628407.000000\n",
      "DUP  count           6.000000\n",
      "     mean      1949836.833333\n",
      "     std       4565609.444010\n",
      "     min           431.000000\n",
      "     25%         50704.500000\n",
      "     50%         93436.500000\n",
      "     75%        178580.250000\n",
      "     max      11268295.000000\n",
      "INV  count          11.000000\n",
      "     mean      1233237.090909\n",
      "     std       3790417.576237\n",
      "     min           292.000000\n",
      "     25%          1978.000000\n",
      "     50%         31715.000000\n",
      "     75%        170471.500000\n",
      "     max      12654098.000000\n",
      "dtype: float64\n",
      "data/sv_size/APGI1955_Tumor-lumpy.tsv\n",
      "sv        \n",
      "BND  count    4.830000e+02\n",
      "     mean     3.396111e+07\n",
      "     std      4.125148e+07\n",
      "     min      5.200000e+01\n",
      "     25%      6.424100e+04\n",
      "     50%      1.498134e+07\n",
      "     75%      5.480461e+07\n",
      "     max      1.639640e+08\n",
      "DEL  count    3.790000e+02\n",
      "     mean     1.227937e+07\n",
      "     std      2.759646e+07\n",
      "     min      1.100000e+01\n",
      "     25%      1.005000e+02\n",
      "     50%      3.500000e+02\n",
      "     75%      1.324638e+06\n",
      "     max      1.493235e+08\n",
      "DUP  count    2.650000e+02\n",
      "     mean     2.062003e+07\n",
      "     std      3.490595e+07\n",
      "     min      8.600000e+01\n",
      "     25%      7.370000e+02\n",
      "     50%      5.999300e+04\n",
      "     75%      3.329168e+07\n",
      "     max      1.623354e+08\n",
      "INV  count    3.000000e+01\n",
      "     mean     1.327667e+02\n",
      "     std      1.241744e+02\n",
      "     min      4.300000e+01\n",
      "     25%      7.525000e+01\n",
      "     50%      9.100000e+01\n",
      "     75%      1.200000e+02\n",
      "     max      5.620000e+02\n",
      "dtype: float64\n",
      "data/sv_size/APGI1955_Tumor-manta.tsv\n",
      "sv        \n",
      "DEL  count           4.000000\n",
      "     mean         1273.250000\n",
      "     std          1650.574723\n",
      "     min            62.000000\n",
      "     25%           155.000000\n",
      "     50%           704.000000\n",
      "     75%          1822.250000\n",
      "     max          3623.000000\n",
      "DUP  count           2.000000\n",
      "     mean     18734575.500000\n",
      "     std      26409853.500010\n",
      "     min         59989.000000\n",
      "     25%       9397282.250000\n",
      "     50%      18734575.500000\n",
      "     75%      28071868.750000\n",
      "     max      37409162.000000\n",
      "INV  count           4.000000\n",
      "     mean      6826285.500000\n",
      "     std       6958525.725364\n",
      "     min          1322.000000\n",
      "     25%       1654558.250000\n",
      "     50%       6161238.000000\n",
      "     75%      11332965.250000\n",
      "     max      14981344.000000\n",
      "dtype: float64\n",
      "data/sv_size/APGI2049_Tumor-lumpy.tsv\n",
      "sv        \n",
      "BND  count    9.400000e+01\n",
      "     mean     1.362557e+07\n",
      "     std      2.709212e+07\n",
      "     min      4.300000e+01\n",
      "     25%      7.802075e+04\n",
      "     50%      1.577750e+06\n",
      "     75%      9.334768e+06\n",
      "     max      1.199353e+08\n",
      "DEL  count    2.450000e+02\n",
      "     mean     1.713773e+06\n",
      "     std      1.014364e+07\n",
      "     min      2.100000e+01\n",
      "     25%      1.010000e+02\n",
      "     50%      2.880000e+02\n",
      "     75%      2.438000e+03\n",
      "     max      1.078829e+08\n",
      "DUP  count    1.120000e+02\n",
      "     mean     5.335883e+06\n",
      "     std      2.175168e+07\n",
      "     min      9.300000e+01\n",
      "     25%      7.097500e+02\n",
      "     50%      1.844500e+03\n",
      "     75%      2.650675e+04\n",
      "     max      1.303658e+08\n",
      "INV  count    1.200000e+01\n",
      "     mean     3.001833e+03\n",
      "     std      6.803292e+03\n",
      "     min      6.800000e+01\n",
      "     25%      9.325000e+01\n",
      "     50%      1.370000e+02\n",
      "     75%      1.947500e+02\n",
      "     max      2.002600e+04\n",
      "dtype: float64\n",
      "data/sv_size/APGI2049_Tumor-manta.tsv\n",
      "sv        \n",
      "DEL  count           4.000000\n",
      "     mean         3682.500000\n",
      "     std          3359.832585\n",
      "     min           191.000000\n",
      "     25%          1516.250000\n",
      "     50%          3326.000000\n",
      "     75%          5492.250000\n",
      "     max          7887.000000\n",
      "DUP  count           5.000000\n",
      "     mean     19631314.600000\n",
      "     std      18742017.333408\n",
      "     min          1147.000000\n",
      "     25%         55057.000000\n",
      "     50%      23626208.000000\n",
      "     75%      36691941.000000\n",
      "     max      37782220.000000\n",
      "INV  count           6.000000\n",
      "     mean      7125993.833333\n",
      "     std      10867785.644802\n",
      "     min            84.000000\n",
      "     25%         20571.750000\n",
      "     50%        392461.500000\n",
      "     75%      13934212.500000\n",
      "     max      23626218.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "samples_size_distr = []\n",
    "\n",
    "for dataset in glob.iglob(os.path.join(tsv_data, \"*.tsv\")):\n",
    "    dataset_name = os.path.basename(dataset)\n",
    "    event_sizes = os.path.join(ev_data, os.path.basename(dataset))\n",
    "    \n",
    "    study = pd.read_table(dataset, dtype=object)\n",
    "    study = normalize(study)\n",
    "    \n",
    "    samples.append((study, dataset_name))\n",
    "    samples_size_distr.append((event_sizes, event_size_distr(event_sizes)))\n",
    "    \n",
    "    # plot them all\n",
    "    hiveplot(dataset_name, study)\n",
    "\n",
    "#sample_summary_table(samples)\n",
    "for fname, data in samples_size_distr:\n",
    "    print fname\n",
    "    #print data[['chrom_a', 'chrom_b', 'sv', 'size']]\n",
    "    print data.groupby(['sv'])['size'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
